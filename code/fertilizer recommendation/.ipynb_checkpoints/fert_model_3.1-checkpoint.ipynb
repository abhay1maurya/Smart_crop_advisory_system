{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fdbe4e1-4eff-4fd6-832d-8ab84296b67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data Loaded. Shape: (5410, 11)\n",
      "   Columns: ['Temperature', 'Moisture', 'Rainfall', 'PH', 'Nitrogen', 'Phosphorous', 'Potassium', 'Carbon', 'Soil', 'Crop', 'Fertilizer']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import randint, uniform\n",
    "import xgboost as xgb\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Load Data\n",
    "# ==============================================================================\n",
    "file_path = 'fertlizer_recommendation_dataset.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"âœ… Data Loaded. Shape: {df.shape}\")\n",
    "    print(f\"   Columns: {df.columns.tolist()}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ CRITICAL ERROR: '{file_path}' not found.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef6b5100-8117-4a39-a2c7-968c90a3ba2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Encoding Labels...\n",
      "   âœ… Encoded Soil: 5 classes\n",
      "   âœ… Encoded Crop: 26 classes\n",
      "   âœ… Encoded Target: 10 unique fertilizers\n",
      "ðŸ”’ Feature Order Locked: ['Temperature', 'Moisture', 'Rainfall', 'PH', 'Soil', 'Crop', 'Nitrogen', 'Potassium', 'Phosphorous', 'Carbon']\n",
      "âœ… Data Split. Training on 4328 samples.\n",
      "âš–ï¸ Scaling Data...\n",
      "âœ… Data Scaled.\n"
     ]
    }
   ],
   "source": [
    "# 2. Encoding (Text -> Numbers)\n",
    "# ==============================================================================\n",
    "encoders = {}\n",
    "print(\"âš™ï¸ Encoding Labels...\")\n",
    "\n",
    "# Encode Features (Using correct column names 'Soil' and 'Crop')\n",
    "for col in ['Soil', 'Crop']:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    encoders[col] = le\n",
    "    print(f\"   âœ… Encoded {col}: {len(le.classes_)} classes\")\n",
    "\n",
    "# Encode Target (Fertilizer)\n",
    "le_target = LabelEncoder()\n",
    "df['Fertilizer'] = le_target.fit_transform(df['Fertilizer'])\n",
    "encoders['Target'] = le_target\n",
    "print(f\"   âœ… Encoded Target: {len(le_target.classes_)} unique fertilizers\")\n",
    "\n",
    "# 3. Feature Setup & Ordering\n",
    "# ==============================================================================\n",
    "# Defining X with the exact column headers from your file\n",
    "# Note: Your file has 'Moisture' and 'Rainfall', but NO 'Humidity'.\n",
    "X = df[['Temperature', 'Moisture', 'Rainfall', 'PH', 'Soil', 'Crop', 'Nitrogen', 'Potassium', 'Phosphorous', 'Carbon']]\n",
    "y = df['Fertilizer']\n",
    "\n",
    "# SAVE FEATURE ORDER (Crucial for API stability)\n",
    "feature_order = X.columns.tolist()\n",
    "print(f\"ðŸ”’ Feature Order Locked: {feature_order}\")\n",
    "\n",
    "# 4. Train/Test Split\n",
    "# ==============================================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"âœ… Data Split. Training on {len(X_train)} samples.\")\n",
    "\n",
    "# 5. Scaling (StandardScaler)\n",
    "# ==============================================================================\n",
    "print(\"âš–ï¸ Scaling Data...\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data ONLY\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# Transform test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"âœ… Data Scaled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0605aaf2-832c-4c6b-8732-8faf459ebdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Configuring Model Architectures for 3-Model Ensemble...\n",
      "âœ… Tuning Configuration Ready.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 6. Hyperparameter Tuning Setup (RF + XGB + KNN)\n",
    "# ==============================================================================\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "import xgboost as xgb # Ensure you have 'pip install xgboost' run separately!\n",
    "\n",
    "print(\"âš™ï¸ Configuring Model Architectures for 3-Model Ensemble...\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. Hyperparameter Tuning Setup (RF + KNN + XGB)\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# 1. Random Forest (RF)\n",
    "rf_base = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "rf_params = {\n",
    "    'n_estimators': randint(150, 300),\n",
    "    'max_depth': [15, 20, 25, None],\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 4)\n",
    "}\n",
    "\n",
    "# 2. K-Nearest Neighbors (KNN)\n",
    "knn_base = KNeighborsClassifier(n_jobs=-1)\n",
    "knn_params = {\n",
    "    'n_neighbors': randint(3, 15),\n",
    "    'weights': ['distance'], \n",
    "    'p': [1, 2]              \n",
    "}\n",
    "\n",
    "# 3. XGBoost (XGB)\n",
    "xgb_base = xgb.XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
    "xgb_params = {\n",
    "    'n_estimators': randint(150, 300),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'subsample': uniform(0.7, 0.3)\n",
    "}\n",
    "\n",
    "# Dictionary to hold the search objects\n",
    "model_searches = {\n",
    "    'rf': RandomizedSearchCV(rf_base, rf_params, n_iter=15, cv=3, scoring='accuracy', n_jobs=-1, random_state=42),\n",
    "    'knn': RandomizedSearchCV(knn_base, knn_params, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=42),\n",
    "    'xgb': RandomizedSearchCV(xgb_base, xgb_params, n_iter=15, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"âœ… Tuning Configuration Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aba2f8a5-90e8-4c28-8b81-bd1a3a081b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting 3-Model Training Pipeline...\n",
      "\n",
      "ðŸ”Ž Tuning RF...\n",
      "   Best Score: 0.9353\n",
      "\n",
      "ðŸ”Ž Tuning KNN...\n",
      "   Best Score: 0.8341\n",
      "\n",
      "ðŸ”Ž Tuning XGB...\n",
      "   Best Score: 0.9360\n",
      "\n",
      "ðŸ—ï¸ Assembling Final Voting Ensemble...\n",
      "\n",
      "âœ… Final 3-Model Ensemble Trained.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 7. Train Optimized Ensemble\n",
    "# ==============================================================================\n",
    "def train_and_assemble(model_searches, X_train_scaled, y_train):\n",
    "    print(\"ðŸš€ Starting 3-Model Training Pipeline...\")\n",
    "    \n",
    "    best_estimators = []\n",
    "    \n",
    "    # Phase 1: Tuning\n",
    "    for name, search in model_searches.items():\n",
    "        print(f\"\\nðŸ”Ž Tuning {name.upper()}...\")\n",
    "        search.fit(X_train_scaled, y_train)\n",
    "        print(f\"   Best Score: {search.best_score_:.4f}\")\n",
    "        best_estimators.append((name, search.best_estimator_))\n",
    "        \n",
    "    # Phase 2: Ensemble Training\n",
    "    print(\"\\nðŸ—ï¸ Assembling Final Voting Ensemble...\")\n",
    "    \n",
    "    # Soft Voting: Averages the probabilities from RF, KNN, and XGB\n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=best_estimators,\n",
    "        voting='soft', \n",
    "        n_jobs=1  # CRITICAL: Set to 1 to prevent Windows crash\n",
    "    )\n",
    "    \n",
    "    # Fit the Ensemble ONCE\n",
    "    ensemble.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "# Execute\n",
    "final_model = train_and_assemble(model_searches, X_train_scaled, y_train)\n",
    "print(\"\\nâœ… Final 3-Model Ensemble Trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f8ed272-6c84-4356-891e-6a28e5c6c524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Evaluating on Test Set...\n",
      "\n",
      "ðŸ† Final Test Accuracy: 95.75%\n",
      "------------------------------------------------------------\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "   Balanced Npk Fertilizer       0.98      0.98      0.98        57\n",
      "                   Compost       0.99      0.98      0.99       108\n",
      "                       Dap       0.97      0.99      0.98       376\n",
      "General Purpose Fertilizer       0.75      0.82      0.78        11\n",
      "                    Gypsum       0.95      0.90      0.93        21\n",
      "                      Lime       0.81      0.87      0.84        54\n",
      "         Muriate Of Potash       0.97      0.96      0.97       106\n",
      "        Organic Fertilizer       0.88      0.92      0.90        38\n",
      "                      Urea       0.92      0.89      0.90        62\n",
      "Water Retaining Fertilizer       0.98      0.95      0.96       249\n",
      "\n",
      "                  accuracy                           0.96      1082\n",
      "                 macro avg       0.92      0.93      0.92      1082\n",
      "              weighted avg       0.96      0.96      0.96      1082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 8. Final Evaluation & Save\n",
    "# ==============================================================================\n",
    "print(\"ðŸ“Š Evaluating on Test Set...\")\n",
    "\n",
    "preds = final_model.predict(X_test_scaled)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(f\"\\nðŸ† Final Test Accuracy: {acc*100:.2f}%\")\n",
    "print(\"-\" * 60)\n",
    "target_names = encoders['Target'].classes_.astype(str)\n",
    "print(classification_report(y_test, preds, target_names=target_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58dbccf2-65ed-4c6b-a616-c2d8df1d0792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Success! Model, Encoders, and Scaler saved to 'fertilizer_model_final.pkl'\n"
     ]
    }
   ],
   "source": [
    "# 9. Save Artifacts (The Deployment Package)\n",
    "# ==============================================================================\n",
    "# Save ALL Artifacts\n",
    "artifacts = {\n",
    "    'model': final_model,\n",
    "    'encoders': encoders,\n",
    "    'scaler': scaler,\n",
    "    'feature_order': feature_order\n",
    "}\n",
    "\n",
    "joblib.dump(artifacts, 'fertilizer_model_final.pkl', compress=3)\n",
    "print(\"ðŸ’¾ Success! Model, Encoders, and Scaler saved to 'fertilizer_model_final.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c55fccf-5e4d-4bfd-8f80-305a3d37c41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Test Prediction:\n",
      "   Recommendation: Urea\n",
      "   Confidence: 86.25%\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 9. Deployment Simulation (Logic for API)\n",
    "# ==============================================================================\n",
    "def predict_fertilizer(temp, moist, rain, ph, soil, crop, N, K, P, C):\n",
    "    # Load everything\n",
    "    data = joblib.load('fertilizer_model_final.pkl')\n",
    "    model = data['model']\n",
    "    encs = data['encoders']\n",
    "    sc = data['scaler']\n",
    "    cols = data['feature_order']\n",
    "    \n",
    "    # Standardize Text\n",
    "    soil_clean = soil.strip().title()\n",
    "    crop_clean = crop.strip().title()\n",
    "    \n",
    "    # Error Handling\n",
    "    if soil_clean not in encs['Soil'].classes_:\n",
    "        return f\"Error: Unknown Soil '{soil}'.\", 0.0\n",
    "    if crop_clean not in encs['Crop'].classes_:\n",
    "        return f\"Error: Unknown Crop '{crop}'.\", 0.0\n",
    "        \n",
    "    try:\n",
    "        # 1. Encode Text -> Numbers\n",
    "        soil_code = encs['Soil'].transform([soil_clean])[0]\n",
    "        crop_code = encs['Crop'].transform([crop_clean])[0]\n",
    "        \n",
    "        # 2. Create DataFrame (Order: Temp, Moist, Rain, PH, Soil, Crop, N, K, P, C)\n",
    "        # Verify this order matches 'feature_order' printed in Cell 2\n",
    "        input_data = pd.DataFrame([[temp, moist, rain, ph, soil_code, crop_code, N, K, P, C]], \n",
    "                                  columns=cols)\n",
    "        \n",
    "        # 3. Scale\n",
    "        input_scaled = sc.transform(input_data)\n",
    "        \n",
    "        # 4. Predict\n",
    "        pred_idx = model.predict(input_scaled)[0]\n",
    "        pred_name = encs['Target'].inverse_transform([pred_idx])[0]\n",
    "        confidence = model.predict_proba(input_scaled)[0][pred_idx] * 100\n",
    "        \n",
    "        return pred_name, confidence\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", 0.0\n",
    "\n",
    "# Run Test\n",
    "# Using 10 features now\n",
    "res, conf = predict_fertilizer(26, 40, 100, 6.5, 'Loamy Soil', 'Rice', 20, 40, 40, 1.0)\n",
    "print(f\"\\nðŸ§ª Test Prediction:\")\n",
    "print(f\"   Recommendation: {res}\")\n",
    "print(f\"   Confidence: {conf:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b2693b-9b92-4413-a6f5-2211e867bac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
